# Churn Analysis

This project analyzes customer churn to identify patterns and predict customer attrition.

## Table of Contents

- [Overview](#overview)
- [Installation](#installation)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [Contributing](#contributing)
- [License](#license)

## Overview

Churn analysis helps businesses understand why customers leave and how to improve retention. This repository contains code and resources for data preprocessing, exploratory analysis, modeling, and evaluation.

## Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/churn_analysis.git
   cd churn_analysis
   ```
2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

## Usage

1. Prepare your dataset in the `data/` directory.
2. Run the analysis scripts:
   ```bash
   python src/analyze.py
   ```
3. Review results in the `output/` directory.

## Project Structure

```
churn_analysis/
‚îú‚îÄ‚îÄ data/
‚îú‚îÄ‚îÄ src/
‚îú‚îÄ‚îÄ output/
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

## Contributing

Contributions are welcome! Please open issues or submit pull requests.

## License

This project is licensed under the MIT License.

---

‚úÖ Etapas j√° implementadas
Carregamento dos dados

Leitura da planilha ‚ÄúE Comm‚Äù e remo√ß√£o de colunas vazias.

Vis√£o geral inicial

Exibi√ß√£o do shape e primeiras linhas do DataFrame.

Mapa de duplicatas e valores faltantes (check de duplicated() e isnull()).

An√°lise univariada

Estat√≠sticas descritivas (mean, median, std, etc.) para colunas num√©ricas.

Distribui√ß√µes e contagens para vari√°veis categ√≥ricas.

An√°lise bivariada

Categ√≥ricas vs. Churn: histograms groupados por status de churn.

Num√©ricas vs. Churn: boxplots/violin plots para cada feature num√©rica.

Matriz de correla√ß√£o

C√°lculo e visualiza√ß√£o (heatmap ou gr√°fico interativo).

Insights sobre multicolinearidade e features correlacionadas ao target.

Detec√ß√£o de outliers & anomalias

IQR univariado (flag de outliers em cada vari√°vel).

Isolation Forest multivariado (flag e escore de anomalia).

Gr√°ficos interativos salvos em HTML.

üõ†Ô∏è Recomenda√ß√µes para completar a an√°lise
Distribui√ß√£o do target (Churn)

Gr√°fico de barras mostrando propor√ß√£o de clientes que churned vs. retained (avalia√ß√£o de balanceamento).

Mapa de missing values

Heatmap ou tabela de contagem de NaN por coluna, para identificar padr√µes de aus√™ncia de dados.

Verifica√ß√£o de tipos e convers√µes

Confirma√ß√£o de que datas, categorias e num√©ricos t√™m os tipos corretos; convers√£o de colunas quando necess√°rio.

Resumo estat√≠stico mais rico

Adi√ß√£o de m√©tricas de skewness, kurtosis e percentis (describe + extras) para detectar enviesamentos.

Distribui√ß√µes cont√≠nuas

KDE plots (ou histograma + curva) para features muito enviesadas (ex.: OrderCount, CashbackAmount).

Intera√ß√µes simples

Pairplot reduzido (2‚Äì3 features mais relevantes) para registrar rela√ß√µes n√£o lineares.

An√°lise de tempo

Se existir componente temporal (datas de pedido, tenure em dias), uma s√©rie temporal ou histograma sobre ‚Äúrecency‚Äù pode ajudar.

Consumo de mem√≥ria

Revisar uso de mem√≥ria do DataFrame e otimizar dtypes para deploy/pipeline.

---

O que j√° foi feito

Explora√ß√£o e pr√©‚Äëprocessamento dos dados

Carregamento e an√°lise explorat√≥ria de application_train.csv e application_test.csv.

Estudo das vari√°veis, identifica√ß√£o de colunas com alto percentual de aus√™ncias e documenta√ß√£o de todos os campos.

Cria√ß√£o de um pipeline de pr√©‚Äëprocessamento que:

Imputa ausentes (num√©ricos com mediana, categ√≥ricos com ‚ÄúUnknown‚Äù).

Escala num√©ricos com RobustScaler e codifica categorias com OneHotEncoder e TargetEncoder.

Garante aus√™ncia de vazamento de informa√ß√£o ao ser aplicado dentro da valida√ß√£o cruzada.

Persist√™ncia do objeto preprocessor.joblib e lista de colunas resultantes (train_columns.csv).

Desenvolvimento de modelos

Baseline com Logistic Regression L2 treinado em 5 folds estratificados; desempenho AUC ‚âà 0,746 e KS ‚âà 0,365.

Experimento com Elastic Net descartado por piora nas m√©tricas.

Migra√ß√£o para LightGBM com ajuste via Optuna; melhoria nas m√©tricas (AUC ‚âà 0,761, KS ‚âà 0,391, P@20 ‚âà 0,212).

Diagn√≥stico de calibra√ß√£o e aplica√ß√£o de regress√£o isot√¥nica nos 5 folds para calibrar as probabilidades (Brier caiu de 0,169 para 0,064 e a reliability curve se aproximou da diagonal
screenshot
).

Defini√ß√£o de um limiar de decis√£o por KS m√°ximo e cria√ß√£o de bandas de risco (Very Low, Low, ‚Ä¶, Very High) com base nas quantis das PDs calibradas; tudo salvo em thresholds_bands.json.

Interpretabilidade

C√°lculo de valores SHAP para o modelo LightGBM; gera√ß√£o de gr√°ficos de import√¢ncia global dos 20 principais atributos
screenshot
.

Prepara√ß√£o de estrutura para explica√ß√µes locais (gr√°ficos waterfall) em Streamlit.

Persist√™ncia de artefatos

Armazenamento de todos os componentes necess√°rios para scoring: preprocessor.joblib, lgbm_model.joblib, isotonic.joblib, feature_names_logreg.csv, thresholds_bands.json, imagens de SHAP e da curva de calibra√ß√£o.

Scripts, API e Dashboard

scripts/preprocess.py implementa fun√ß√µes para carregar artefatos e pontuar novos dados com atribui√ß√£o de bandas de risco.

api.py exp√µe um servi√ßo FastAPI com /score_one e /score_batch, retornando PD bruta, PD calibrada, banda de risco e decis√£o aprovar/declinar, al√©m de um endpoint de health check.

streamlit_app.py oferece um painel interativo no qual √© poss√≠vel carregar arquivos CSV para pontua√ß√£o em lote ou inserir manualmente dados de um cliente e visualizar a explica√ß√£o SHAP local (cascata).

üõ†Ô∏è O que pode melhorar para um projeto profissional

Organiza√ß√£o de pacotes: extrair as fun√ß√µes de scoring duplicadas no api.py e no streamlit_app.py para um m√≥dulo utilit√°rio √∫nico (por ex. scripts/preprocess.score_df), evitando diverg√™ncias na l√≥gica.

Script de treinamento: o arquivo train_model.py est√° vazio; seria interessante migrar as etapas de treinamento dos notebooks para um script parametrizado para facilitar re‚Äëtreinos e CI/CD.

Documenta√ß√£o:

Completar o README.md com uma descri√ß√£o clara do problema, fluxo de modelagem, instru√ß√µes de setup (como instalar depend√™ncias, rodar notebooks, API e Streamlit) e exemplos de uso.

Adicionar coment√°rios e docstrings nos scripts principais (preprocess.py, api.py, streamlit_app.py) para melhorar a legibilidade.

Valida√ß√£o extra:

Adicionar um conjunto de testes unit√°rios simples para verificar se a pipeline est√° carregando e se o API retorna os campos esperados.

Considerar m√©tricas adicionais (Precision@k, Recall@k) e algum tipo de an√°lise de fairness se houver requisitos legais.

Controle de vers√£o de dados: explicitar onde os dados brutos ficam armazenados (pasta data/raw) e n√£o version√°‚Äëlos no GitHub; usar .gitignore para arquivos grandes e sens√≠veis.

Ambiente de depend√™ncias: garantir que requirements.txt esteja atualizado e possua vers√µes testadas, al√©m de opcionalmente fornecer um environment.yml para quem preferir Conda.

Automa√ß√£o de deploy: criar scripts para subir a API e o Streamlit em um servi√ßo (Heroku, Render, etc.) ou mesmo Dockerizar a aplica√ß√£o para facilitar a execu√ß√£o em outras m√°quinas.

üì¶ Etapas para finalizar e subir ao GitHub

Limpar o reposit√≥rio:

Remover dados brutos sens√≠veis ou grandes; manter somente um ‚Äúsample‚Äù ou instru√ß√µes para download.

Eliminar arquivos tempor√°rios ou redundantes do Jupyter.

Completar train_model.py (ou renome√°‚Äëlo) com o pipeline completo de treinamento e salvamento de artefatos.

Refatorar o c√≥digo para centralizar a l√≥gica de pontua√ß√£o e calibra√ß√£o em um √∫nico m√≥dulo e importar essa fun√ß√£o no API e no Streamlit.

Atualizar o README.md com descri√ß√£o, instru√ß√µes de instala√ß√£o (pip install -r requirements.txt), como rodar notebooks, como executar a API (uvicorn app.api:app --reload) e como iniciar o painel (streamlit run app/streamlit_app.py).

Adicionar testes b√°sicos e um pytest.ini se desejar ir al√©m.

Fazer commit estruturado: criar reposit√≥rio no GitHub, adicionar todos os scripts e notebooks relevantes, documentar no hist√≥rico as principais etapas.

Publicar: push para GitHub, configurar reposit√≥rio como portf√≥lio p√∫blico e, se desejar, adicionar badges de build, documenta√ß√£o e link para demo online.

Com essas melhorias e passos finais, seu projeto de credit‚Äërisk estar√° pronto para ser apresentado como parte de seu portf√≥lio profissional.
